{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pickle\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "import sklearn.manifold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import multiprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import time\n",
    "import collections\n",
    "from scipy import stats \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"wiki.txt\", \"r\",errors='ignore').read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus is now 94298560 characters long\n"
     ]
    }
   ],
   "source": [
    "print(\"Corpus is now {0} characters long\".format(len(file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the corpus into sentences\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "raw_sentences = tokenizer.tokenize(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert into a list of words\n",
    "#remove unnecessary, split into words, no hyphens\n",
    "#list of words\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean=re.sub('[\\n]',' ',raw.lower())\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw.lower())\n",
    "    words = clean.split()\n",
    "    #words = [ps.stem(w) for w in words if not w in stop_words]  \n",
    "    words = [w for w in words if not w in stop_words] \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence where each word is tokenized\n",
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))\n",
    "#print(sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corpus contains 7,976,868 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(\"The corpus contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordList(sentences,minCount):\n",
    "    wordList = []\n",
    "    count = Counter()\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            count[word] += 1\n",
    "    for word,c in count.items():\n",
    "        if c >= minCount:\n",
    "            wordList.append(word)\n",
    "    return wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordList=getWordList(sentences,minCount=5) # for min frequency of a word which should be 5\n",
    "#print(WordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23079"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vocab Size\n",
    "len(WordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62960183"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "ab=list(itertools.chain.from_iterable(sentences))\n",
    "new_str =' '.join(ab)  \n",
    "open('wiki_clean.txt', 'w').write(new_str) # writing clean text to new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Word2Vec(sentences,size=100,window=1,min_count=5,seed=42,workers=multiprocessing.cpu_count(),batch_words=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Word2Vec(sentences,size=100,window=1,min_count=5,seed=102,workers=multiprocessing.cpu_count(),batch_words=1) # the two embedding spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_frequency\n",
    "w2c = dict()\n",
    "for item in model1.wv.vocab:\n",
    "    w2c[item]=model1.wv.vocab[item].count\n",
    "w2cSorted=dict(sorted(w2c.items(), key=lambda x: x[1],reverse=True))\n",
    "# reverse output word and their frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stability(word,similar1,similar2):    \n",
    "    overlap=0\n",
    "    for i in range(len(similar1)):\n",
    "        for j in range(len(similar2)):\n",
    "            if similar1[i][0] == similar2[j][0]:\n",
    "                overlap=overlap+1\n",
    "    return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.96875 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()\n",
    "with open('swiki.csv', 'a',errors='replace') as the_file:\n",
    "    the_file.write('Word,Stability(%),Stability(%) IU,Frequency\\n')\n",
    "    for word in WordList:\n",
    "        similar1=model1.wv.most_similar(word, topn=10)\n",
    "        similar2=model2.wv.most_similar(word, topn=10)\n",
    "        stab=Stability(word,similar1,similar2)\n",
    "        the_file.write(word+','+str(stab*10)+','+str(stab*100/(20-stab))+','+str(w2cSorted[word])+'\\n')\n",
    "print (time.process_time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('swiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787001.530289456\n"
     ]
    }
   ],
   "source": [
    "df['Stability(%) IU'] = pd.to_numeric(df['Stability(%) IU'])\n",
    "s = df['Stability(%) IU'].sum()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#window size 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Word2Vec(sentences,size=100,window=3,min_count=5,seed=42,workers=multiprocessing.cpu_count(),batch_words=1) # the two embedding spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Word2Vec(sentences,size=100,window=3,min_count=5,seed=102,workers=multiprocessing.cpu_count(),batch_words=1) # the two embedding spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2c = dict()\n",
    "for item in model3.wv.vocab:\n",
    "    w2c[item]=model3.wv.vocab[item].count\n",
    "w2cSorted=dict(sorted(w2c.items(), key=lambda x: x[1],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175.734375 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()\n",
    "with open('swiki3.csv', 'a',errors='replace') as the_file:\n",
    "    the_file.write('Word,Stability(%),Stability(%) IU,Frequency\\n')\n",
    "    for word in WordList:\n",
    "        similar1=model3.wv.most_similar(word, topn=10)\n",
    "        similar2=model4.wv.most_similar(word, topn=10)\n",
    "        stab=Stability(word,similar1,similar2)\n",
    "        the_file.write(word+','+str(stab*10)+','+str(stab*100/(20-stab))+','+str(w2cSorted[word])+'\\n')\n",
    "print (time.process_time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('swiki3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761534.9740043238\n"
     ]
    }
   ],
   "source": [
    "df['Stability(%) IU'] = pd.to_numeric(df['Stability(%) IU'])\n",
    "s = df['Stability(%) IU'].sum()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15166037, 15953736)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.train(sentences, total_examples=model5.corpus_count, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7582001, 7976868)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.train(sentences, total_examples=model6.corpus_count, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2c = dict()\n",
    "for item in model3.wv.vocab:\n",
    "    w2c[item]=model3.wv.vocab[item].count\n",
    "w2cSorted=dict(sorted(w2c.items(), key=lambda x: x[1],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459.046875 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()\n",
    "with open('swikiepoch.csv', 'a',errors='replace') as the_file:\n",
    "    the_file.write('Word,Stability(%),Stability(%) IU')\n",
    "    for word in WordList:\n",
    "        similar1=model3.wv.most_similar(word, topn=10)\n",
    "        similar2=model4.wv.most_similar(word, topn=10)\n",
    "        stab=Stability(word,similar1,similar2)\n",
    "        the_file.write(word+','+str(stab*10)+','+str(stab*100/(20-stab))+'\\n')\n",
    "print (time.process_time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('swikiepoch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100157.8652255896\n"
     ]
    }
   ],
   "source": [
    "#df['Stability(%) IU'] = pd.to_numeric(df['Stability(%) IU'])\n",
    "s = df['Stability(%) IUaction'].sum()\n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
